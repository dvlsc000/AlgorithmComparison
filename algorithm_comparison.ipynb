{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on Custom Sensor Dataset\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "- Load data from custom files: \"dataset.txt\", \"features\", and \"targets\"\n",
    "- Perform exploratory data analysis and preprocessing\n",
    "- Scale features and split data for training/testing\n",
    " - Train and evaluate four classifiers: SVM, Logistic Regression, Random Forest, and kNN\n",
    "\n",
    "**Files Expected:**\n",
    " - dataset.txt: Contains the sensor readings, whitespace-delimited.\n",
    " - features: Contains feature indices and names (e.g., \"1 tBodyAcc-mean()-X\").\n",
    " - targets: Contains one target label per row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Read the feature matrix, feature names, and target labels from the provided files.\n",
    "\n",
    "Adjust the file paths below if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for the dataset\n",
    "dataset_file = 'dataset.txt'\n",
    "features_file = 'features'\n",
    "targets_file = 'targets'\n",
    "\n",
    "# Load the feature data (assuming whitespace-delimited, no header)\n",
    "X = pd.read_csv(dataset_file, delim_whitespace=True, header=None)\n",
    "print(\"Dataset shape:\", X.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
